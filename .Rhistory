1 - 1/50 # 98% > 97% (confiança desejada)
plot_ci(lower_vector, upper_vector, mean(population)) # gráfico apresentou 1 linha vermelha
1 - 1/50 # 98% > 97% (confiança desejada)
desvio_padrao <- 5
media <- 50
desvio_padrao <- 5
pnorm(25.2, mean = media, sd = desvio_padrao, lower.tail = T)
pnorm(24.8, mean = media, sd = desvio_padrao, lower.tail = T)
x <- pnorm(25.2, mean = media, sd = desvio_padrao, lower.tail = T)
y <- pnorm(24.8, mean = media, sd = desvio_padrao, lower.tail = T)
x-y
media <- 25
desvio_padrao <- 5
x <- pnorm(25.2, mean = media, sd = desvio_padrao, lower.tail = T)
y <- pnorm(24.8, mean = media, sd = desvio_padrao, lower.tail = T)
x-y
1-(x-y)
desvio_padrao <- sqrt(variancia)
tamanho <- 400
z <- 0.2
variancia <- 25
desvio_padrao <- sqrt(variancia)
erro_padrao <- desvio_padrao / sqrt(tamanho)
valor_critico <- z_calculado / erro_padrao
tamanho <- 400
z_calculado <- 0.2
variancia <- 25
desvio_padrao <- sqrt(variancia)
erro_padrao <- desvio_padrao / sqrt(tamanho)
valor_critico <- z_calculado / erro_padrao
prob <- 1 - 2 * pnorm(valor_critico, 0, 1, lower.tail = F)
prob
desvio_padrao <- sqrt(variancia)
limite_superior <- media * 3.25 * desvio_padrao / sqrt(tamanho)
limite_superior
# a) limite superior para intervalo de confiança 99%
tamanho <- 10
media <- 345
variancia <- 100
desvio_padrao <- sqrt(variancia)
limite_superior <- media * 3.25 * desvio_padrao / sqrt(tamanho)
limite_superior
# a) limite superior para intervalo de confiança 99%
tamanho <- 15
media <- 345
variancia <- 100
desvio_padrao <- sqrt(variancia)
limite_superior <- media * 3.25 * desvio_padrao / sqrt(tamanho)
limite_superior
# a) limite superior para intervalo de confiança 99%
tamanho <- 15
media <- 345
variancia <- 100
desvio_padrao <- sqrt(variancia)
limite_superior <- media + 3.25 * desvio_padrao / sqrt(tamanho)
limite_superior
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
qt(0.995, df)
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
qt(0.995, tamanho - 1)
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
qt(0.995, 10 - 1)
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
qt(0.995, tamanho - 1)
qt(0.995, tamanho - 1)
limite_superior <- media + 2.976843 * desvio_padrao / sqrt(tamanho)
limite_superior
limite_superior
1/100/2
1- 1/100/2
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
1- 10/100/2
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
1- 10/100/2
qt(0.95, tamanho - 1) # 2.976843
# b) amplitude do intervalo bilateral de confiança de 90%
# calcular z
1- 10/100/2 # 0.95
qt(0.95, tamanho - 1) #  1.76131
amplitude <- 2 * 1.76131 * desvio_padrao / sqrt(tamanho)
amplitude
# c) tamamnho da amostra para intervalo de confiança de 90% apresentasse amplitude de no máximo 5 unidades
amplitude <- 5
sqrt(tamanho) <- 2 * 1.76131 * desvio_padrao / amplitude
tamanho <- (2 * 1.76131 * desvio_padrao / amplitude)^2
tamanho
# c) tamamnho da amostra para intervalo de confiança de 90% apresentasse amplitude de no máximo 5 unidades
amplitude <- 5
tamanho <- (2 * 1.76131 * desvio_padrao / amplitude)^2
tamanho
test_antes <- c(128, 128, 126, 118, 128, 120)
test_depois <- c(120,	120,	130,	114,	120,	116)
t.test(test_antes, test_depois, paired=T, alternative="greater")
qt(0.95, tamanho - 1) #  1.76131
intervalo_confianca <- 99/100
p <- 1/2
desvio <- 0.045
z <- 2.57 # 99%
n <- (z/desvio)^2 * p * (1 - p)
n
p <- 0.15
desvio <- 0.045
z <- 2.57 # 99%
n <- (z/desvio)^2 * p * (1 - p)
n
teste_pro <- c(30, 40, 45, 26, 37, 33, 33, 28)
teste_apt <- c(18, 19, 22, 16, 25, 22, 21, 20)
modelo <- lm(teste_pro ~ teste_apt)
summary(modelo)
# ExercÃ­cio 4 Ajuste um novo modelo que utilize a variÃ¡vel homeruns para
# predizer runs (pontos). Utilizando as estimativas dos resultados do R,
# escreva a equaÃ§Ã£o da linha de regressÃ£o. O que a inclinaÃ§Ã£o (coef. angular)
# nos diz sobre a relaÃ§Ã£o entre o sucesso de um time e seus home runs?
plot(mlb11$homeruns, mlb11$runs)
cor(mlb11$runs, mlb11$homeruns)
m2 <- lm(runs ~ homeruns, data = mlb11)
summary(m2)
summary(modelo)
# c.
apt <- 20
pro <- 8.283 + 1.262 * apt
pro
# d.
# pro <- 8.283 + 1.262 * apt
pro <- 44
apt <- (pro - 8.283) / 1.262
apt
setwd("C:/Dev/github/cd002-trabalho-pratico")
# Para criar o agrupamento hierÃ¡rquico, de forma a visualizar de forma aninhada
# os clusters encontrados, precisaremos trabalhar com variÃ¡veis numÃ©ricas.
# Por isso, as colunas tÃ­tulo, artista, top.genre e added foram excluÃ­das.
# O campo added tambÃ©m foi excluÃ­do, pois nÃ£o agrega na tarefa de agrupamento,
# nÃ£o hÃ¡ relaÃ§Ã£o com quando a mÃºsica foi lanÃ§ada (year.released), por fim, seus valores
# estÃ£o concentrados em datas especÃ­ficas.
spotify_numeric <- spotify[-c(1:3, 5)]
#instala pacotes necessarios (psych para usar funcao describe)
install.packages("psych")
install.packages("ggplot")
#pacotes necessarios
library(readr)
library(psych)
#library(tidyverse)
library(ggplot2)
library('fastDummies')
library(NbClust)
library(factoextra)
library(dplyr)
library(stringr)
library(dendextend)
#leitura da base
spotify <- read.csv("data/Spotify 2010 - 2019 Top 100.csv",stringsAsFactors=TRUE, encoding = 'UTF-8')
#exploracao da base
View(spotify)
str(spotify)
#sumarizacao das variÃ¡veis numÃ©ricas
#summary(spotify)
#mean | standard deviation | min | max | range | standard error
describe(spotify[ , c('dnce', 'nrgy', 'dB', 'spch', 'acous', 'live', 'bpm', 'dur', 'pop')], fast=TRUE)
#Histogramas das variÃ¡veis numÃ©ricas
ggplot(data = spotify, aes(x = dnce)) + geom_histogram() + ggtitle('DanÃ§abilidade - QuÃ£o fÃ¡cil Ã© danÃ§ar a mÃºsica')
ggplot(data = spotify, aes(x = nrgy)) + geom_histogram() + ggtitle('Energia - QuÃ£o energÃ©tica Ã© a mÃºsica')
ggplot(data = spotify, aes(x = dB)) + geom_histogram() + ggtitle('Decibel - QuÃ£o alta Ã© a mÃºsica')
ggplot(data = spotify, aes(x = spch)) + geom_histogram() + ggtitle('Cantado - QuÃ£o a mÃºsica Ã© focada na palavra falada')
ggplot(data = spotify, aes(x = acous)) + geom_histogram() + ggtitle('AcÃºstica - QuÃ£o acÃºstica Ã© a mÃºsica')
ggplot(data = spotify, aes(x = live)) + geom_histogram() + ggtitle('Ao Vivo - O quanto se parece com uma gravaÃ§Ã£o ao vivo')
ggplot(data = spotify, aes(x = bpm)) + geom_histogram() + ggtitle('Beats Per Minute - Ritmo da mÃºsica')
ggplot(data = spotify, aes(x = dur)) + geom_histogram() + ggtitle('DuraÃ§Ã£o da mÃºsica em segundos')
ggplot(data = spotify, aes(x = pop)) + geom_histogram() + ggtitle('Popularidade da mÃºsica (nÃ£o Ã© um ranking)')
spotify1 <- spotify[, c('dnce', 'nrgy', 'dB', 'spch', 'acous', 'live', 'bpm', 'dur', 'pop')]
#grafico de pairs
pairs(spotify1)
ggcorr(spotify1)
ggcorr(spotify1, nbreaks = 4, palette = "RdGy", label = TRUE, label_size = 3, label_color = "white")
# Para criar o agrupamento hierÃ¡rquico, de forma a visualizar de forma aninhada
# os clusters encontrados, precisaremos trabalhar com variÃ¡veis numÃ©ricas.
# Por isso, as colunas tÃ­tulo, artista, top.genre e added foram excluÃ­das.
# O campo added tambÃ©m foi excluÃ­do, pois nÃ£o agrega na tarefa de agrupamento,
# nÃ£o hÃ¡ relaÃ§Ã£o com quando a mÃºsica foi lanÃ§ada (year.released), por fim, seus valores
# estÃ£o concentrados em datas especÃ­ficas.
spotify_numeric <- spotify[-c(1:3, 5)]
spotify_numeric <- dummy_cols(spotify_numeric, select_columns = 'artist.type')
spotify_numeric <- spotify_numeric[-c(13)]
spotify_numeric <- spotify_numeric[-c(13)]
str(spotify_numeric)
# Outra tarefa bastante importante Ã© a normalizaÃ§Ã£o, pois para o cÃ¡lculo das distÃ¢ncias
# temos que minimizar as distorÃ§Ãµes decorrentes de unidades ou dispersÃµes distintas
# entre as variÃ¡veis, deixando-as com o mesmo peso.
z <- spotify_numeric
means <- apply(z,2,mean)
sds <- apply(z,2,sd)
spotify_numeric <- scale(z,center=means,scale=sds)
# Dendograma incial.
# Depois da criaÃ§Ã£o da matriz de distÃ¢ncias criamos um dendograma inicial.
# Contudo, como se trata de uma base com 1000 registros, a identificaÃ§Ã£o de
# cada observaÃ§Ã£o individualmente fica confusa.
dista=dist(spotify_numeric, method="euclidean")
dista.hc=hclust(d=dista, method="ward.D")
fviz_dend(dista.hc, cex=0.5)
# Uma forma de contornar esse problema Ã© visualizar apenas um trecho da Ã¡rvore
# criada, com isso podemos analisar um pedaÃ§o do grÃ¡fico de acordo com um corte.
# Abaixo criamos um corte de altura 7, onde podemos reparar a parte superior dessa altura.
hc <- hclust(dist(spotify_numeric))
hcd <- as.dendrogram(hc)
plot(cut(hcd, h=7)$upper,
main="Partde de cima do corte h=7")
# De forma anÃ¡loga ao diagrama anterior, tambÃ©m podemos focar nossa atenÃ§Ã£o na
# parte de baixo de alguma altura especÃ­fica.
# Abaixo criamos uma visualizaÃ§Ã£o da parte inferior ao corte de altura 10.
plot(cut(hcd, h=10)$lower[[2]],
main="Second branch of lower tree with cut at h=10")
# Outra forma de melhorar o entendimento dos dados Ã© demarcar os clusters de
# interesse em um diagrama hierÃ¡rquico.
# Como nossas classes de interesse sÃ£o os valores encontradas no campo new.genre,
# iremos realizar o agrupamento em 12 clusters, que Ã© justamente o valor de
# classes do campo.
# As Ã¡reas demarcadas, cada uma com uma cor diferente Ã© a representaÃ§Ã£o de onde
# cada observaÃ§Ã£o foi agrupada (de acordo com a distÃ¢ncia calculada).
plot(dista.hc, labels=FALSE)
#leitura da base
spotify <- read.csv("data/Spotify 2010 - 2019 Top 100.csv",stringsAsFactors=TRUE)
summary(spotify)
# visualizando gêneros
barplot(table(spotify$top.genre))
utils::View(table(spotify$top.genre))
summary(spotify)
# visualizando gêneros
barplot(table(spotify$top.genre))
utils::View(table(spotify$top.genre))
spotify_numeric <- dummy_cols(spotify_numeric, select_columns = 'artist.type')
# Para criar o agrupamento hierÃ¡rquico, de forma a visualizar de forma aninhada
# os clusters encontrados, precisaremos trabalhar com variÃ¡veis numÃ©ricas.
# Por isso, as colunas tÃ­tulo, artista, top.genre e added foram excluÃ­das.
# O campo added tambÃ©m foi excluÃ­do, pois nÃ£o agrega na tarefa de agrupamento,
# nÃ£o hÃ¡ relaÃ§Ã£o com quando a mÃºsica foi lanÃ§ada (year.released), por fim, seus valores
# estÃ£o concentrados em datas especÃ­ficas.
spotify_numeric <- spotify[-c(1:3, 5)]
spotify_numeric <- dummy_cols(spotify_numeric, select_columns = 'artist.type')
spotify1 <- spotify[, c("bpm", "nrgy", "dnce", "dB", "spch")]
summary(spotify1)
# melhorando a classificação de generos agrupando eles
# visualizando gêneros
barplot(table(spotify$top.genre))
spotify_genre1 <- as.data.frame(table(spotify$top.genre))
library(dplyr)
library(stringr)
spotify <- spotify %>%
mutate(
new.genre = case_when(
str_detect(top.genre, 'pop')  ~ "pop",
str_detect(top.genre, 'rock')  ~ "rock",
str_detect(top.genre, 'hip hop')  ~ "hip hop",
str_detect(top.genre, 'country')  ~ "country",
str_detect(top.genre, 'indie')  ~ "indie",
str_detect(top.genre, 'rap')  ~ "rap",
str_detect(top.genre, 'r&b')  ~ "r&b",
str_detect(top.genre, 'house')  ~ "house",
str_detect(top.genre, 'edm')  ~ "edm",
str_detect(top.genre, 'soul')  ~ "soul",
str_detect(top.genre, 'alternative')  ~ "alternative",
TRUE ~ "unknown"
)
)
barplot(table(spotify$new.genre))
spotify_genre2 <- as.data.frame(table(spotify$new.genre))
spotify1 <- spotify[, c("bpm", "nrgy", "dnce", "dB", "spch")]
summary(spotify1)
# Visualizando as distancias entre os objetos
#
library(factoextra)
distance <- get_dist(spotify1)
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
#comparando as matrizes de contingencia e relacinando com os SSE dos clusters
table(spotify$top.genre, spotify_kmi3$cluster)
# rodando o kmeans com 3 grupos, o melhor resultado de 10 e visualizando o resultado
spotify_kmi1 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi1
spotify_kmi1$centers
spotify_kmi1$size
spotify_kmi1$tot.withinss
spotify_kmi1$cluster
# cluster plot
fviz_cluster(spotify_kmi1, data = spotify1)
# plotando os agrupamentos de objetos, no caso de mais de duas variaveis, de acordo com seus componentes principais
plot(spotify1, col=spotify_kmi1$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
# gerando uma matriz de contingencia e avaliando o SSE intra-clusters e total
table(spotify$top.genre, spotify_kmi1$cluster)
table(spotify$new.genre, spotify_kmi1$cluster)
## gerando agrupamentos com diferentes numeros de clusters
spotify_kmi3 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi5 <- kmeans(spotify1, centers=5, nstart = 10)
spotify_kmi10 <- kmeans(spotify1, centers=10, nstart = 10)
spotify_kmi20 <- kmeans(spotify1, centers=20, nstart = 10)
spotify_kmi50 <- kmeans(spotify1, centers=50, nstart = 10)
# visualizando os resultados
p3 <- fviz_cluster(spotify_kmi3, geom = "point", data = spotify1) + ggtitle("k = 3")
p5 <- fviz_cluster(spotify_kmi5, geom = "point",  data = spotify1) + ggtitle("k = 5")
p10 <- fviz_cluster(spotify_kmi10, geom = "point",  data = spotify1) + ggtitle("k = 10")
p20 <- fviz_cluster(spotify_kmi20, geom = "point",  data = spotify1) + ggtitle("k = 20")
p50 <- fviz_cluster(spotify_kmi50, geom = "point",  data = spotify1) + ggtitle("k = 50")
library(gridExtra)
grid.arrange(p1, p5, p10, p20, p50, nrow = 2)
grid.arrange(p3, p5, p10, p20, p50, nrow = 2)
#comparando as matrizes de contingencia e relacinando com os SSE dos clusters
table(spotify$top.genre, spotify_kmi3$cluster)
table(spotify$top.genre, spotify_kmi5$cluster)
table(spotify$top.genre, spotify_kmi10$cluster)
table(spotify$top.genre, spotify_kmi20$cluster)
table(spotify$top.genre, spotify_kmi50$cluster)
table(spotify$new.genre, spotify_kmi3$cluster)
table(spotify$new.genre, spotify_kmi5$cluster)
table(spotify$new.genre, spotify_kmi10$cluster)
table(spotify$new.genre, spotify_kmi20$cluster)
table(spotify$new.genre, spotify_kmi50$cluster)
spotify_kmi3$withinss
spotify_kmi3$tot.withinss
# Elbow method
set.seed(123)
fviz_nbclust(spotify1 , kmeans, method = "wss", k.max=50)
?fviz_nbclust
table(spotify$artist.type, spotify_kmi3$cluster)
# melhorando a classificação de generos agrupando eles
# visualizando gêneros
barplot(table(spotify$top.genre))
spotify_genre1 <- as.data.frame(table(spotify$top.genre))
utils::View(table(spotify$top.genre))
utils::View(table(spotify$top.genre))
utils::View(table(spotify$top.genre))
spotify_genre1 <- as.data.frame(table(spotify$top.genre))
utils::View(table(spotify$top.genre))
spotify <- spotify %>%
mutate(
new.genre = case_when(
str_detect(top.genre, 'pop')  ~ "pop",
str_detect(top.genre, 'rock')  ~ "rock",
str_detect(top.genre, 'hip hop')  ~ "hip hop",
str_detect(top.genre, 'country')  ~ "country",
str_detect(top.genre, 'indie')  ~ "indie",
str_detect(top.genre, 'rap')  ~ "rap",
str_detect(top.genre, 'r&b')  ~ "r&b",
str_detect(top.genre, 'house')  ~ "house",
str_detect(top.genre, 'edm')  ~ "edm",
str_detect(top.genre, 'soul')  ~ "soul",
str_detect(top.genre, 'alternative')  ~ "alternative",
TRUE ~ "unknown"
)
)
barplot(table(spotify$new.genre))
spotify_genre2 <- as.data.frame(table(spotify$new.genre))
utils::View(table(spotify$new.genre))
spotify1 <- spotify[, c("bpm", "nrgy", "dnce", "dB", "spch")]
summary(spotify1)
# Visualizando as distancias entre os objetos
#
library(factoextra)
distance <- get_dist(spotify1)
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
?fviz_dist
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
?fviz_dist
spotify1 <- spotify[, c("bpm"")]
summary(spotify1)
# Visualizando as distancias entre os objetos
#
library(factoextra)
distance <- get_dist(spotify1)
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
spotify1 <- spotify[, c("bpm")]
summary(spotify1)
# Visualizando as distancias entre os objetos
#
library(factoextra)
distance <- get_dist(spotify1)
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# rodando o kmeans com 3 grupos, o melhor resultado de 10 e visualizando o resultado
spotify_kmi1 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi1
spotify_kmi1$centers
spotify_kmi1$size
spotify_kmi1$tot.withinss
spotify_kmi1$cluster
# cluster plot
fviz_cluster(spotify_kmi1, data = spotify1)
# plotando os agrupamentos de objetos, no caso de mais de duas variaveis, de acordo com seus componentes principais
plot(spotify1, col=spotify_kmi1$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
# gerando uma matriz de contingencia e avaliando o SSE intra-clusters e total
table(spotify$top.genre, spotify_kmi1$cluster)
table(spotify$new.genre, spotify_kmi1$cluster)
## gerando agrupamentos com diferentes numeros de clusters
spotify_kmi3 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi5 <- kmeans(spotify1, centers=5, nstart = 10)
spotify_kmi10 <- kmeans(spotify1, centers=10, nstart = 10)
spotify_kmi20 <- kmeans(spotify1, centers=20, nstart = 10)
spotify_kmi50 <- kmeans(spotify1, centers=50, nstart = 10)
# visualizando os resultados
p3 <- fviz_cluster(spotify_kmi3, geom = "point", data = spotify1) + ggtitle("k = 3")
p5 <- fviz_cluster(spotify_kmi5, geom = "point",  data = spotify1) + ggtitle("k = 5")
p10 <- fviz_cluster(spotify_kmi10, geom = "point",  data = spotify1) + ggtitle("k = 10")
p20 <- fviz_cluster(spotify_kmi20, geom = "point",  data = spotify1) + ggtitle("k = 20")
p50 <- fviz_cluster(spotify_kmi50, geom = "point",  data = spotify1) + ggtitle("k = 50")
library(gridExtra)
grid.arrange(p3, p5, p10, p20, p50, nrow = 2)
#comparando as matrizes de contingencia e relacinando com os SSE dos clusters
table(spotify$top.genre, spotify_kmi3$cluster)
table(spotify$artist.type, spotify_kmi3$cluster)
table(spotify$new.genre, spotify_kmi3$cluster)
table(spotify$new.genre, spotify_kmi5$cluster)
table(spotify$new.genre, spotify_kmi10$cluster)
spotify1 <- spotify[, c("bpm", "nrgy", "dnce", "dB", "spch")]
summary(spotify1)
# Visualizando as distancias entre os objetos
#
library(factoextra)
distance <- get_dist(spotify1)
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# rodando o kmeans com 3 grupos, o melhor resultado de 10 e visualizando o resultado
spotify_kmi1 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi1
spotify_kmi1$centers
spotify_kmi1$size
spotify_kmi1$tot.withinss
spotify_kmi1$cluster
# cluster plot
fviz_cluster(spotify_kmi1, data = spotify1)
# plotando os agrupamentos de objetos, no caso de mais de duas variaveis, de acordo com seus componentes principais
plot(spotify1, col=spotify_kmi1$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
# gerando uma matriz de contingencia e avaliando o SSE intra-clusters e total
table(spotify$top.genre, spotify_kmi1$cluster)
table(spotify$new.genre, spotify_kmi1$cluster)
## gerando agrupamentos com diferentes numeros de clusters
spotify_kmi3 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi5 <- kmeans(spotify1, centers=5, nstart = 10)
spotify_kmi10 <- kmeans(spotify1, centers=10, nstart = 10)
spotify_kmi20 <- kmeans(spotify1, centers=20, nstart = 10)
spotify_kmi50 <- kmeans(spotify1, centers=50, nstart = 10)
# visualizando os resultados
p3 <- fviz_cluster(spotify_kmi3, geom = "point", data = spotify1) + ggtitle("k = 3")
p5 <- fviz_cluster(spotify_kmi5, geom = "point",  data = spotify1) + ggtitle("k = 5")
p10 <- fviz_cluster(spotify_kmi10, geom = "point",  data = spotify1) + ggtitle("k = 10")
p20 <- fviz_cluster(spotify_kmi20, geom = "point",  data = spotify1) + ggtitle("k = 20")
p50 <- fviz_cluster(spotify_kmi50, geom = "point",  data = spotify1) + ggtitle("k = 50")
library(gridExtra)
grid.arrange(p3, p5, p10, p20, p50, nrow = 2)
grid.arrange(p3, p5, p10, nrow = 1)
# plotando os agrupamentos de objetos, no caso de mais de duas variaveis, de acordo com seus componentes principais
plot(spotify1, col=spotify_kmi1$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi3$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi5$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi5$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi10$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi5$cluster,
main = paste("k-means clustering com 5 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi10$cluster,
main = paste("k-means clustering com 10 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
# Elbow method
set.seed(123)
fviz_nbclust(spotify1 , kmeans, method = "wss", k.max=50)
fviz_nbclust(spotify1 , kmeans, method = "wss", k.max=25)
# gráfico de similariade
fviz_dist(distance,
gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# rodando o kmeans com 3 grupos, o melhor resultado de 10 e visualizando o resultado
spotify_kmi1 <- kmeans(spotify1, centers=3, nstart = 10)
spotify_kmi1
spotify_kmi1$centers
spotify_kmi1$size
spotify_kmi1$tot.withinss
spotify_kmi1$cluster
# cluster plot
fviz_cluster(spotify_kmi1, data = spotify1)
p10 <- fviz_cluster(spotify_kmi10, geom = "point",  data = spotify1) + ggtitle("k = 10")
fviz_cluster(spotify_kmi10, geom = "point",  data = spotify1) + ggtitle("k = 10")
grid.arrange(p3, p5, p10, nrow = 1)
plot(spotify1, col=spotify_kmi3$cluster,
main = paste("k-means clustering com 3 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi5$cluster,
main = paste("k-means clustering com 5 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi10$cluster,
main = paste("k-means clustering com 10 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi10$cluster,
main = paste("k-means clustering com 10 grupos; Total do SSE = ",spotify_kmi1$tot.withinss))
plot(spotify1, col=spotify_kmi10$cluster,
main = paste("k-means clustering com 10 grupos; Total do SSE = "))
plot(spotify1, col=spotify_kmi10$cluster,
main = paste("k-means clustering com 10 grupos"))
table(spotify$new.genre, spotify_kmi10$cluster)
utils::View(table(spotify$top.genre))
